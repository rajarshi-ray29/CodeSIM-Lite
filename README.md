<!-- 
# Official Code Generation Repository for KagNLP 
- [Visit our webpage](https://kagnlp.github.io/codesim.github.io/)
- Visit our paper for more details -->

# CodeSim-Lite: Modernising CodeSIM for Efficient Local Code Generation


<p align="center">
‚Ä¢ üë®‚Äçüíª <a href="https://github.com/rajarshi-ray29/CodeSIM-Lite" target="_blank">Code</a>
‚Ä¢ üìÉ <a href="https://docs.google.com/document/d/1AU-lCgNFXcPZLYMvreJ-HCO48LHOJwlxqYar43o1fRM/edit?usp=sharing" target="_blank">Report</a>
‚Ä¢ üì∞ <a href="https://docs.google.com/presentation/d/11PesPY0Jl8wRCRxDOdnSVQj1sxUU7lt-ZqY0RhPbalc/edit?usp=sharing" target="_blank">Slides</a>
</p>

## Abstract

CodeSIM-Lite is a lightweight adaptation of the original CodeSIM framework designed for efficient local code generation using quantized open-source LLMs like Gemma-2-9B and CodeLlama-7B. Motivated by hardware constraints and privacy concerns in local environments, this project re-architects the original CodeSIM pipeline with a smaller agent loop, reduced prompt length, and support for 4-bit inference via NF4 quantization. Despite a significantly reduced computational footprint, CodeSIM-Lite preserves solution quality and debugging capacity on HumanEval and similar benchmarks.

This work is an independent class project that builds upon and modifies components from the original [CodeSIM repository](https://github.com/kagnlp/CodeGenerator). Full credit for the design of the original multi-agent framework and planning-coding-debugging loop goes to the authors of the paper below.

## Reference Implementation

We base our implementation on:

> **CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging**  
> Md. Ashraful Islam, Mohammed Eunus Ali, Md Rizwan Parvez  
> [arXiv:2502.05664](https://arxiv.org/abs/2502.05664)

## Running CodeSIM-Lite

### 1. Clone our repository:
```bash
git clone https://github.com/rajarshi-ray29/CodeSIM-Lite && cd CodeSIM-Lite
```

### 2. Create a virtual environment and install dependencies:
```bash
pip install -r requirements.txt
```

### 3. Run the CodeSIM-Lite pipeline:
```bash
python src/main.py --dataset HumanEval --strategy CodeSIM --model_provider HuggingFace --model gemma-2-9b
```

The code is compatible with quantized HuggingFace models (e.g., Gemma, CodeLlama) and supports options for tuning plan/debug iterations, prompt length, and early-stopping heuristics. See the README.md and run.py --help for additional arguments.


## CodeSim Overview
Our goal in this project is to adapt and optimize a multi-agent code generation framework for efficient local execution using quantized open-source LLMs. While our work builds on the original CodeSIM framework, our contributions focus on restructuring the agent loop, reducing prompt length, and enabling execution on consumer-grade GPUs with minimal performance loss. The following description of the planning, coding, and debugging agents has been taken directly from the CodeSIM paper to acknowledge its foundational role and to contextualize our modifications.

![CodeSim Overview](./images/CodeSim-Overview.png)


### ¬ª Planning Agent

The first component of CodeSIM is the *Planning Agent*. Given a problem description, the *Planning Agent* generates a single exemplar‚Äîa relevant problem along with its plan and solution. This mimics the behavior of human programmers, who, when faced with a new problem, first recall a similar problem they've previously solved. This exemplar-based recall is crucial as it provides a starting point for constructing a solution plan. Instead of generating multiple ungrounded exemplars as in MapCoder, our agent focuses on only one at a time. We then instruct the LLM to generate an appropriate plan. Once the plan is created, the LLM simulates (step-by-step) the solution with a sample input. If the simulation result does not match the expected output, the agent prompts the LLM to revise the plan. Otherwise, the plan is deemed valid. In the case of failure, the *Planning Agent* refines the plan.

### ¬ª Coding Agent

Next component is the *Coding Agent*, which takes the problem description and the plan generated by the *Planning Agent* as input. The role of this agent is to translate the plan into executable code that solves the given problem. Once the code is generated, CodeSIM evaluates it using sample input/output test cases. If the code passes all sample tests, it is returned as the final solution. Otherwise, the code is handed over to the next agent for further refinement.

### ¬ª Debugging Agent

The final component, the *Debugging Agent*, receives the original problem, the plan from the *Planning Agent*, the code generated by the *Coding Agent*, and the execution (unit testing) log as input to debug the code. To identify bugs, instead of directly prompting the LLMs, we uniquely leverage the simulation once again. The LLM is instructed specifically to simulate the code on inputs where it fails to produce the expected output, allowing it to trace the execution step by step and locate the error. Once the bug is identified, the LLM modifies the code to resolve the issue.

## Acknowledgements

We acknowledge the original authors of CodeSIM for their contribution to the design and implementation of the original multi-agent code generation framework:

```bibtex
@misc{islam2025codesim,
    title={CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging},
    author={Md. Ashraful Islam and Mohammed Eunus Ali and Md Rizwan Parvez},
    year={2025},
    eprint={2502.05664},
    archivePrefix={arXiv},
    primaryClass={cs.CL},
    url={https://arxiv.org/abs/2502.05664},
}
```

## Disclaimer
This project is an academic class submission intended to explore resource-efficient adaptations of state-of-the-art multi-agent code generation systems. It is independently developed and not affiliated with the original authors or their institutions.
